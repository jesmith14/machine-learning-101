{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-4604/5604 HW2: Linear Classification \n",
    "\n",
    "### Solution by: Jessie Smith (Jess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment overview\n",
    "\n",
    "News agencies, governments and corporations sometimes track social media during natural disasters to try to monitor unfolding events. But because no single person or group of people can read all available Twitter data, organizations may turn to natural language processing methods to try and understand what is happening as disasters unfold. \n",
    "\n",
    "While this approach is powerful, inferring events from NLP can be tricky. For instance, say a person [tweets](https://twitter.com/AnyOtherAnnaK/status/629195955506708480) that \"LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE.\" This tweet includes the word \"ablaze\", which may signal to a computer that there is an unfolding disaster. However, in this particular case, the person is speaking metaphorically. A simple computer system using keywords (e.g. ablaze) might be fooled into thinking the tweet is reporting an actual fire.\n",
    "\n",
    "In this assignment, you will predict if a given tweet actually refers to a natural disaster. This exercise is motivated by real-world disaster monitoring systems, and can help you to gain practice with supervised binary classification and natural language processing.\n",
    "\n",
    "__Note__: This dataset originally comes from [Kaggle](https://www.kaggle.com/c/nlp-getting-started/overview). But it has been modified for this problem set. Information about the data from this problem set that you find on Kaggle will almost certainly be wrong.\n",
    "\n",
    "### What to hand in\n",
    "\n",
    "You will submit the assignment on Canvas. Submit a single Jupyter notebook named `hw2lastname.ipynb`, where lastname is replaced with your last name. **Please also submit a PDF or HTML version of your notebook to Canvas**.\n",
    "\n",
    "Please clearly mark all deliverables. You are encouraged to create additional cells in whatever way makes the presentation more organized and easy to follow. You are allowed to import additional Python libraries.\n",
    "\n",
    "### Submission policies\n",
    "\n",
    "- **Collaboration:** You are allowed to work with one partner. You are still expected to write up your own solution. Each individual must turn in their own submission, and list your collaborators after your name.\n",
    "- **Late submissions:** Each student may use up to 5 late days over the semester. You have late days, not late hours. This means that if your submission is late by any amount of time past the deadline, then this will use up a late day. If it is late by any amount beyond 24 hours past the deadline, then this will use a second late, and so on. Once you have used up all late days, late assignments will be given at most 80% credit after one day and 60% credit after two days.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "In this assignment, you will experiment with perceptron and logistic regression in `sklearn`. Much of the code has already been written for you. We will use a class called `SGDClassifier` (which you should read about in the [sklearn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)), which  implements stochastic gradient descent (SGD) for a variety of loss functions, including both perceptron and logistic regression, so this will be a way to easily move between the two classifiers.\n",
    "\n",
    "The code below will load the datasets. There are two data collections: the \"training\" data, which contains the tweets that you will use for training the classifiers, and the \"testing\" data, which are tweets that you will use to measure the classifier accuracy. The test tweets are instances the classifier has never seen before, so they are a good way to see how the classifier will behave on data it hasn't seen before. However, we still know the labels of the test tweets, so we can measure the accuracy.\n",
    "\n",
    "For this problem, we will use what are called \"bag of words\" features, which are commonly used when doing classification with text. Each feature is a word, and the value of a feature for a particular tweet is number of times the word appears in the tweet (with value $0$ if the word does not appear in the tweet).\n",
    "\n",
    "A note on labels: **If `Y_train` or `Y_test` are 1 this means the tweet refers to a real disaster; if the values are 0, it means the tweet does not refer to a real disaster** \n",
    "\n",
    "Run the block of code below to load the data. You don't need to do anything yet. Move on to \"Problem 1\" next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "Y_train = df_train[\"target\"]\n",
    "text_train = df_train[\"text\"]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(text_train)\n",
    "feature_names = np.asarray(vec.get_feature_names())\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "Y_test = df_test[\"target\"]\n",
    "text_test = df_test[\"text\"]\n",
    "\n",
    "X_test = vec.transform(text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id keyword location  \\\n",
       "0           0   1     NaN      NaN   \n",
       "1           2   5     NaN      NaN   \n",
       "2           3   6     NaN      NaN   \n",
       "3           4   7     NaN      NaN   \n",
       "4           5   8     NaN      NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1  All residents asked to 'shelter in place' are ...       1  \n",
       "2  13,000 people receive #wildfires evacuation or...       1  \n",
       "3  Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "4  #RockyFire Update => California Hwy. 20 closed...       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id keyword location  \\\n",
       "0           1   4     NaN      NaN   \n",
       "1           7  13     NaN      NaN   \n",
       "2          16  24     NaN      NaN   \n",
       "3          18  26     NaN      NaN   \n",
       "4          26  38     NaN      NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0             Forest fire near La Ronge Sask. Canada       1  \n",
       "1  I'm on top of the hill and I can see a fire in...       1  \n",
       "2                                      I love fruits       0  \n",
       "3                                  My car is so fast       0  \n",
       "4                              Was in NYC last week!       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6120 1493\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 1\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6120, 18594)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ROWS, COLUMNS OF TRAINING DATA (Number of columns are the features)\n",
    "X_train.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x18594 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6120 2644\n",
      "0.4320261437908497\n"
     ]
    }
   ],
   "source": [
    "#Percentage of instances about actual disasters in the training data\n",
    "print(len(df_train), df_train['target'].sum())\n",
    "print(df_train['target'].sum()/len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Understand the data [3 points]\n",
    "\n",
    "Before doing anything else, take time to understand the code above.\n",
    "\n",
    "The variables `df_train` and `df_test` are dataframes that store the training (and testing) datasets, which are contained in comma-separated files where the first column is the label and the second column is the text of the tweet.\n",
    "\n",
    "The [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class converts the raw text into a bag-of-words into a feature vector representation that `sklearn` can use.\n",
    "\n",
    "You should print out the values of the variables and write any other code needed to answer the following questions.\n",
    "\n",
    "#### Deliverable 1.1\n",
    "\n",
    "How many training instances are in the dataset? How many test instances?\n",
    "\n",
    "Training instances: 6120\n",
    "Testing instances: 1493\n",
    "\n",
    "#### Deliverable 1.2\n",
    "\n",
    "How many features are in the training data?\n",
    "\n",
    "There are 18594 features (columns) in the training data\n",
    "\n",
    "\n",
    "#### Deliverable 1.3\n",
    "\n",
    "What is the distribution of labels in the training data? That is, what percentage of instances are about actual disasters?\n",
    "\n",
    "About 43% of the instances are about actual disasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Perceptron [3 points]\n",
    "\n",
    "The code below trains an [`SGDClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) using the perceptron loss, then it measures the accuracy of the classifier on the test data, using `sklearn`'s [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. \n",
    "\n",
    "The `fit` function trains the classifier. The feature weights are stored in the `coef_` variable after training. The `predict` function of the trained `SGDClassifier` outputs the predicted label for a given instance or list of instances.\n",
    "\n",
    "Additionally, this code displays the features and their weights in sorted order, which you may want to examine to understand what the classifier is learning. In general, in binary classification, the 0 class is considered the \"negative\" class.\n",
    "\n",
    "There are 3 keyword arguments that have been added to the code below. It is important you keep the same values of these arguments whenever you create an `SGDClassifier` instance in this assignment so that you get consistent results. They are:\n",
    "\n",
    "- `max_iter` is one of the stopping criteria, which is the maximum number of iterations/epochs the algorithm will run for.\n",
    "\n",
    "- `tol` is the other stopping criterion, which is how small the difference between the current loss and previous loss should be before stopping.\n",
    "\n",
    "- `random_state` is a seed for pseudorandom number generation. The algorithm uses randomness in the way the training data are sorted, which will affect the solution that is learned, and even the accuracy of that solution.\n",
    "\n",
    "Note: *Wait a minute $-$ in class we learned that the loss function is convex, so the algorithm will find the same minimum regardless of how it is trained. Why is there random variation in the output? The reason is that even though there is only one minimum value of the loss, there may be different weights that result in the same loss, so randomness is a matter of tie-breaking. What's more, while different weights may have the same loss, they could lead to different classification accuracies, because the loss function is not the same as accuracy. (Unless accuracy was your loss function... which is possible, but uncommon because it turns out to be a difficult function to optimize.)\n",
    "Note that different computers may still give different answers, despite keeping these settings the same, because of how pseudorandom numbers are generated with different operating systems and Python environments.*\n",
    "\n",
    "To begin, run the code in the cell below without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SGD iterations: 35\n",
      "Training accuracy: 0.987908\n",
      "Testing accuracy: 0.781648\n",
      "\n",
      "Feature weights:\n",
      "\n",
      " - lowest\n",
      "\t zy3hpdjnwg: -0.7900\n",
      "\t qzlpfhpwdo: -0.6970\n",
      "\t better: -0.5112\n",
      "\t f7wqpcekg2: -0.5112\n",
      "\t sun: -0.5112\n",
      "\n",
      " - highest\n",
      "\t storm: 0.8829\n",
      "\t sunburned: 0.9294\n",
      "\t hurricane: 0.9294\n",
      "\t massacre: 1.0688\n",
      "\t earthquake: 1.2547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "classifier = SGDClassifier(loss='perceptron', max_iter=1000, tol=1.0e-12, random_state=123, eta0=100)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Number of SGD iterations: %d\" % classifier.n_iter_)\n",
    "print(\"Training accuracy: %0.6f\" % accuracy_score(Y_train, classifier.predict(X_train)))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(Y_test, classifier.predict(X_test)))\n",
    "\n",
    "print(\"\\nFeature weights:\")\n",
    "args = np.argsort(classifier.coef_[0])\n",
    "\n",
    "print(\"\\n - lowest\")\n",
    "for a in args[0:5]:\n",
    "    print(\"\\t %s: %0.4f\" % (feature_names[a], classifier.coef_[0][a]))\n",
    "   \n",
    "print(\"\\n - highest\")\n",
    "for a in args[-5:]:\n",
    "    print(\"\\t %s: %0.4f\" % (feature_names[a], classifier.coef_[0][a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 2.1\n",
    "\n",
    "Based on the training accuracy, do you conclude that the data are (mostly) linearly separable? Why or why not?\n",
    "\n",
    "Yes, because the accuracy is nearly 1.0 (which would indicate that the data was perfectly linearly sepearable), but there may be a few outliers or we may have just reached the stopping criteria before that 1.0 accuracy was reached.\n",
    "\n",
    "#### Deliverable 2.2\n",
    "\n",
    "Which feature most increases the likelihood that the tweet does not refer to a real disaster, and which feature most increases the likelihood that the tweet refers to a real disaster? \n",
    "\n",
    "1. The feature that increases the likelihood of NOT referring to a real disaster is the word 'zy3hpdjnwg' existing in the tweet (umm... not sure who would even be tweeting that giberish?!), because is has the lowest weight: -0.7900\n",
    "2. The feature that increases the likelihood of REFERRING to a real disaster is the word 'earthquake' existing in the tweet, because it has the highest weight: 1.2547 (also, this data may be a bit biased if that is the highest weighted feature, because it means there were a lot of positively classified tweets with 'earthquake' but there are other natural disasters not represented in this list of the 5 highest words!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 2.3 \n",
    "One technique for improving the resulting model with perceptron is to take an average of the weight vectors learned at different iterations of the algorithm, rather than only using the final weights that minimize the loss. That is, calculate $\\bar{\\mathbf{w}} = \\sum_{t=1}^T \\mathbf{w}^{(t)}$ where $\\mathbf{w}^{(t)}$ is the weight vector at iteration $t$ of the algorithm and $T$ is the number of iterations, and then use $\\bar{\\mathbf{w}}$ when making classifications on new data.\n",
    "\n",
    "To use this technique in your classifier, add the keyword argument `average=True` to the `SGDClassifier` function. Try it now using the cells below.\n",
    "\n",
    "Compare the initial training/test accuracies to the training/test accuracies after doing averaging. What happens? Why do you think averaging the weights from different iterations has this effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SGD iterations: 35\n",
      "Training accuracy: 0.977124\n",
      "Testing accuracy: 0.811788\n",
      "\n",
      "Feature weights:\n",
      "\n",
      " - lowest\n",
      "\t full: -1.6394\n",
      "\t sun: -1.3797\n",
      "\t better: -1.3130\n",
      "\t also: -1.3088\n",
      "\t book: -1.2684\n",
      "\n",
      " - highest\n",
      "\t storm: 2.0315\n",
      "\t earthquake: 2.0326\n",
      "\t floods: 2.0351\n",
      "\t fires: 2.1129\n",
      "\t hiroshima: 2.1832\n"
     ]
    }
   ],
   "source": [
    "classifier = SGDClassifier(loss='perceptron', max_iter=1000, tol=1.0e-12, random_state=123, eta0=100, average=True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Number of SGD iterations: %d\" % classifier.n_iter_)\n",
    "print(\"Training accuracy: %0.6f\" % accuracy_score(Y_train, classifier.predict(X_train)))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(Y_test, classifier.predict(X_test)))\n",
    "\n",
    "print(\"\\nFeature weights:\")\n",
    "args = np.argsort(classifier.coef_[0])\n",
    "\n",
    "print(\"\\n - lowest\")\n",
    "for a in args[0:5]:\n",
    "    print(\"\\t %s: %0.4f\" % (feature_names[a], classifier.coef_[0][a]))\n",
    "   \n",
    "print(\"\\n - highest\")\n",
    "for a in args[-5:]:\n",
    "    print(\"\\t %s: %0.4f\" % (feature_names[a], classifier.coef_[0][a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable (interpretation): \n",
    "\n",
    "Using the average of the weights rather than the final weights made the training accuracy decrease a small amount (-0.01), but made the testing accuracy increase by a somewhat descent amount (+0.3)! This could have happened because maybe without averaging, our final weights ended up at a local minimum -- but by averaging, we can take the best weights from the entire training process (not just where we ended up), which can make for a more generalizable solution, which is why we achieved better testing accuracy because we weren't overfit to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Logistic regression [4 points]\n",
    "\n",
    "For this problem, create a new `SGDClassifier`, this time setting the `loss` argument to `'log'`, which will train a logistic regression classifier. Set `average=False` for the remaining problems.\n",
    "\n",
    "Once you have trained the classifier, you can use the `predict` function to get the classifications, as with perceptron. Additionally, logistic regression provides probabilities for the predictions. You can get the probabilities by calling the `predict_proba` function. This will give a list of two numbers; the first is the probability that the class is $0$ and the second is the probability that the class is $1$.\n",
    "\n",
    "\n",
    "For the first task, add the keyword argument `alpha` to the `SGDClassifier` function. This is the regularization strength, called $\\lambda$ in lecture. If you don't specify `alpha`, it defaults to $0.0001$. Experiment with other values and see how this affects the outcome.\n",
    "\n",
    "#### Deliverable 3.1: \n",
    "\n",
    "Calculate the training and testing accuracy when `alpha` is one of $[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]$. Create a plot where the x-axis is `alpha` and the y-axis is accuracy, with two lines (one for training and one for testing). You can borrow the code from HW1 for generating plots in Python. Use [a log scale for the x-axis](https://matplotlib.org/examples/pylab_examples/log_demo.html) so that the `alpha` values are spaced evenly.\n",
    "\n",
    "[your solution should be plotted below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA:  0.0001\n",
      "Training accuracy: 0.983333\n",
      "Testing accuracy: 0.807770\n",
      "ALPHA:  0.001\n",
      "Training accuracy: 0.901634\n",
      "Testing accuracy: 0.813798\n",
      "ALPHA:  0.01\n",
      "Training accuracy: 0.808660\n",
      "Testing accuracy: 0.773610\n",
      "ALPHA:  0.1\n",
      "Training accuracy: 0.710784\n",
      "Testing accuracy: 0.695244\n",
      "ALPHA:  1.0\n",
      "Training accuracy: 0.674183\n",
      "Testing accuracy: 0.665104\n",
      "ALPHA:  10.0\n",
      "Training accuracy: 0.657026\n",
      "Testing accuracy: 0.661755\n",
      "ALPHA:  100.0\n",
      "Training accuracy: 0.567484\n",
      "Testing accuracy: 0.580040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-1119126e73904e40bc3a4c56b8116b67\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1119126e73904e40bc3a4c56b8116b67\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1119126e73904e40bc3a4c56b8116b67\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d35e814045a4228c1591f19760431f67\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"data type\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"alpha\", \"scale\": {\"type\": \"log\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-d35e814045a4228c1591f19760431f67\": [{\"alpha\": 0.0001, \"data type\": \"train\", \"accuracy\": 0.9833333333333333}, {\"alpha\": 0.001, \"data type\": \"train\", \"accuracy\": 0.9016339869281046}, {\"alpha\": 0.01, \"data type\": \"train\", \"accuracy\": 0.8086601307189543}, {\"alpha\": 0.1, \"data type\": \"train\", \"accuracy\": 0.7107843137254902}, {\"alpha\": 1.0, \"data type\": \"train\", \"accuracy\": 0.6741830065359478}, {\"alpha\": 10.0, \"data type\": \"train\", \"accuracy\": 0.6570261437908497}, {\"alpha\": 100.0, \"data type\": \"train\", \"accuracy\": 0.5674836601307189}, {\"alpha\": 0.0001, \"data type\": \"test\", \"accuracy\": 0.8077695914266577}, {\"alpha\": 0.001, \"data type\": \"test\", \"accuracy\": 0.8137977227059612}, {\"alpha\": 0.01, \"data type\": \"test\", \"accuracy\": 0.7736101808439384}, {\"alpha\": 0.1, \"data type\": \"test\", \"accuracy\": 0.695244474212994}, {\"alpha\": 1.0, \"data type\": \"test\", \"accuracy\": 0.6651038178164769}, {\"alpha\": 10.0, \"data type\": \"test\", \"accuracy\": 0.6617548559946417}, {\"alpha\": 100.0, \"data type\": \"test\", \"accuracy\": 0.580040187541862}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "\n",
    "# starter code\n",
    "alphas = [0.0001,0.001,0.01,0.1,1.0,10.0,100.0]\n",
    "training_acc = []\n",
    "testing_acc = []\n",
    "for a in alphas:\n",
    "    classifier = SGDClassifier(loss='log', max_iter=1000, alpha=a, tol=1.0e-12, random_state=123, eta0=100, average=False)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    train_acc = accuracy_score(Y_train, classifier.predict(X_train))\n",
    "    test_acc = accuracy_score(Y_test, classifier.predict(X_test))\n",
    "    print('ALPHA: ', a)\n",
    "    print(\"Training accuracy: %0.6f\" % train_acc)\n",
    "    print(\"Testing accuracy: %0.6f\" % test_acc)\n",
    "    training_acc.append(train_acc)\n",
    "    testing_acc.append(test_acc)\n",
    "\n",
    "test_or_train = ['train'] * len(alphas) + ['test'] * len(alphas)\n",
    "df = pd.DataFrame({\"alpha\": alphas + alphas,\n",
    "                   \"data type\":test_or_train,\n",
    "                   \"accuracy\":training_acc + testing_acc})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('alpha', scale=alt.Scale(type='log')),\n",
    "    color=\"data type\", \n",
    "    y='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.2\n",
    "\n",
    "Examine the classifier probabilities using the `predict_proba` function when training with different values of `alpha`. What do you observe? How does `alpha` affect the prediction probabilities, and why do you think this happens?\n",
    "\n",
    "\n",
    "## My Answer: \n",
    "(Code is below to support my theory)\n",
    "It would appear that as the alpha value is increased, the probability of predicting a \"1\" (probability of predicting that this text is indicative of a natural disaster) decreases, and the probability of predicting a \"0\" (that this text is not indicative of a natural disaster) increases. With a really low alpha value, the probability of predicting a \"1\" is really high and the probability of predicting a \"0\" is really low. But as alpha is increased, the probability of predicting either a \"0\" or a \"1\" is almost the same, it's basically 50/50.\n",
    "\n",
    "I think this happens because since alpha is the regularization strength, when you have a really low alpha, the algorithm can overfit to the training data because it isn't making a bit impact. But when alpha is really big it will impact the minimization of our loss (because our loss gets really BIG so we try to make the weights really SMALL to minimize the loss). So basically our algorithm starts off really overfit (basically only predicting \"1\"s) with a small alpha. But with an alpha that is too big, our algorithm is underfit because there is too much bias that we added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA VALUE:  0.0001\n",
      "[[0.1073517  0.8926483 ]\n",
      " [0.07474336 0.92525664]\n",
      " [0.04847949 0.95152051]\n",
      " ...\n",
      " [0.00976061 0.99023939]\n",
      " [0.04878059 0.95121941]\n",
      " [0.00382533 0.99617467]]\n",
      "ALPHA VALUE:  0.001\n",
      "[[0.35321656 0.64678344]\n",
      " [0.16869801 0.83130199]\n",
      " [0.13702526 0.86297474]\n",
      " ...\n",
      " [0.03844073 0.96155927]\n",
      " [0.18279678 0.81720322]\n",
      " [0.03216899 0.96783101]]\n",
      "ALPHA VALUE:  0.01\n",
      "[[0.53629373 0.46370627]\n",
      " [0.32635411 0.67364589]\n",
      " [0.30038956 0.69961044]\n",
      " ...\n",
      " [0.18228622 0.81771378]\n",
      " [0.32799007 0.67200993]\n",
      " [0.18481425 0.81518575]]\n",
      "ALPHA VALUE:  0.1\n",
      "[[0.54681201 0.45318799]\n",
      " [0.46917619 0.53082381]\n",
      " [0.44543801 0.55456199]\n",
      " ...\n",
      " [0.44182658 0.55817342]\n",
      " [0.46094343 0.53905657]\n",
      " [0.41797239 0.58202761]]\n",
      "ALPHA VALUE:  1.0\n",
      "[[0.51459256 0.48540744]\n",
      " [0.50241214 0.49758786]\n",
      " [0.49491548 0.50508452]\n",
      " ...\n",
      " [0.5094737  0.4905263 ]\n",
      " [0.49789611 0.50210389]\n",
      " [0.49055035 0.50944965]]\n",
      "ALPHA VALUE:  10.0\n",
      "[[0.50239332 0.49760668]\n",
      " [0.50106973 0.49893027]\n",
      " [0.50015043 0.49984957]\n",
      " ...\n",
      " [0.50220857 0.49779143]\n",
      " [0.50048597 0.49951403]\n",
      " [0.49968586 0.50031414]]\n",
      "ALPHA VALUE:  100.0\n",
      "[[0.50056581 0.49943419]\n",
      " [0.50043237 0.49956763]\n",
      " [0.50033777 0.49966223]\n",
      " ...\n",
      " [0.50055279 0.49944721]\n",
      " [0.50037189 0.49962811]\n",
      " [0.50029223 0.49970777]]\n"
     ]
    }
   ],
   "source": [
    "#Code to justify my thoughts for ^^\n",
    "for a in alphas:\n",
    "    classifier = SGDClassifier(loss='log', max_iter=1000, alpha=a, tol=1.0e-12, random_state=123, eta0=100, average=False)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print(\"ALPHA VALUE: \", a)\n",
    "    print(classifier.predict_proba(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.3: \n",
    "\n",
    "Now remove the `alpha` argument so that it goes back to the default value. We'll now look at the effect of the learning rate. By default, `sklearn` uses an \"optimal\" learning rate based on some heuristics that work well for many problems. However, it can be good to see how the learning rate can affect the algorithm.\n",
    "\n",
    "For this task, add the keyword argument `learning_rate` to the `SGDClassifier` function and set the value to `invscaling`. This defines the learning rate at iteration $t$ as: $\\eta_t = \\frac{\\eta_0}{t^a}$, where $\\eta_0$ and $a$ are both arguments you have to define in the `SGDClassifier` function, called `eta0` and `power_t`, respectively. Experiment with different values of `eta0` and `power_t` and see how they affect the number of iterations it takes the algorithm to converge. You will often find that it will not finish within the maximum of $1000$ iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  10\n",
      "POWER_T:  0.5\n",
      "CONVERGENCE ITERS:  177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  10\n",
      "POWER_T:  1.0\n",
      "CONVERGENCE ITERS:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  10\n",
      "POWER_T:  2.0\n",
      "CONVERGENCE ITERS:  1000\n",
      "ETA_0:  100\n",
      "POWER_T:  0.5\n",
      "CONVERGENCE ITERS:  94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  100\n",
      "POWER_T:  1.0\n",
      "CONVERGENCE ITERS:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  100\n",
      "POWER_T:  2.0\n",
      "CONVERGENCE ITERS:  1000\n",
      "ETA_0:  1000\n",
      "POWER_T:  0.5\n",
      "CONVERGENCE ITERS:  105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  1000\n",
      "POWER_T:  1.0\n",
      "CONVERGENCE ITERS:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA_0:  1000\n",
      "POWER_T:  2.0\n",
      "CONVERGENCE ITERS:  1000\n",
      "ETA_0:  10000\n",
      "POWER_T:  0.5\n",
      "CONVERGENCE ITERS:  88\n",
      "ETA_0:  10000\n",
      "POWER_T:  1.0\n",
      "CONVERGENCE ITERS:  126\n",
      "ETA_0:  10000\n",
      "POWER_T:  2.0\n",
      "CONVERGENCE ITERS:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "etas = [10, 100, 1000, 10000]\n",
    "power_ts = [0.5, 1.0, 2.0]\n",
    "for e in etas:\n",
    "    for p in power_ts:\n",
    "        classifier = SGDClassifier(loss='log', \n",
    "                                   max_iter=1000, \n",
    "                                   learning_rate='invscaling', \n",
    "                                   eta0=e, \n",
    "                                   power_t=p, \n",
    "                                   tol=1.0e-12, \n",
    "                                   random_state=123,\n",
    "                                   average=False)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        print(\"ETA_0: \", e)\n",
    "        print(\"POWER_T: \", p)\n",
    "        print(\"CONVERGENCE ITERS: \", classifier.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the table below with the number of iterations for values of `eta0` in $[10.0, 100.0, 1000.0, 10000.0]$ and values of `power_t` in $[0.5, 1.0, 2.0]$. You may find it easier to write python code that can output the markdown for the table, but if you do that place the output here. If it does not converge within the maximum number of iterations (set to $1000$ by `max_iter`), record $1000$ as the number of iterations. You will need to read the documentation for this class to learn how to recover the actual number of iterations before reaching the stopping criterion.\n",
    "\n",
    "| `eta0`   | `power_t` | # Iterations |\n",
    "|:----------|:-:|:------------:|\n",
    "| $10.0$    | $0.5$     |    $177$       |\n",
    "| $10.0$    | $1.0$     |       $1000$       |\n",
    "| $10.0$    | $2.0$     |   $1000$           |\n",
    "| $100.0$   | $0.5$     |   $94$           |\n",
    "| $100.0$   | $1.0$     |   $1000$           |\n",
    "| $100.0$   | $2.0$     |   $1000$           |\n",
    "| $1000.0$  | $0.5$     |   $105$           |\n",
    "| $1000.0$  | $1.0$     |   $1000$           |\n",
    "| $1000.0$  | $2.0$     |   $1000$           |\n",
    "| $10000.0$ | $0.5$     |   $88$           |\n",
    "| $10000.0$ | $1.0$     |   $126$           |\n",
    "| $10000.0$ | $2.0$     |   $1000$           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\eta_t = \\frac{\\eta_0}{t^a}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.4\n",
    "\n",
    "Describe how `eta0` and `power_t` affect the learning rate based on the formula (e.g., if you increase `power_t`, what will this do to the learning rate?), and connect this to what you observe in the table above.\n",
    "\n",
    "## My answer: \n",
    "eta0 and power_t affect the learning rate because $\\eta_t = \\frac{\\eta_0}{t^a}$, so the larger that eta0 is, the larger the learning rate is. And subsequently, the larger that power_t is, the smaller the learning rate is. This means that in theory, with a large eta_0 (and large learning rate) the model might learn VERY quickly because it is allowed to take bigger steps to minimize loss. Inversley, making power_t larger (and making the learning rate smaller) might make the model learn more slowly because of taking small steps towards the minimum loss, it might even never converge by the max iterations of 1000. That being said, with a large learning rate, you could also just get unlucky and overshoot the mark continuously and never converge either, so you have to be careful to not let it get TOO large.\n",
    "\n",
    "Now taking this theoretical background and appllying it to the results in the table, my theory is pretty solid. The largest size of eta_0 (10000) produced some of the lowest iterations before convergence (88 and 126). And the largest power_t consistently led to the model never converging before 1000 iterations!\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove the `learning_rate`, `eta0`, and `power_t` arguments so that the learning rate returns to the default setting. For this final task, we will experiment with how high the probabiity must be before an instance is classified as positive.\n",
    "\n",
    "The code below includes a function called `threshold` which takes as input the classification probabilities of the data (called `probs`, which is given by the function `predict_proba`) and a threshold (called `tau`, a scalar that should be a value between $0$ and $1$). It will classify each instance as $1$ if the probability of being $1$ is greater than `tau`, otherwise it will classify the instance as $0$. Note that if you set `tau` to $0.5$, the `threshold` function should give you exactly the same output as the classifier `predict` function.\n",
    "\n",
    "You should find that increasing the threshold causes the accuracy to drop. This makes sense, because you are classifying some things as 0 even though it's more probable that they are 1. So why do this? Suppose you care more about accurately identifying tweets about natural disasters than missing tweets about disasters (e.g. maybe you forward these tweets to first responders.) You thus want to be confident that when you classify a tweet as 1 that it really is 1.\n",
    "\n",
    "There is a metric called _precision_ which measures something like accuracy but for one specific class. Whereas accuracy is the percentage of tweets that were correctly classified, the precision of 1 would be the percentage of tweets classified as 1 that were correctly classified. (In other words, the number of tweets classified as 1 whose correct label was 1, divided by the number of tweets classified as 1.)\n",
    "\n",
    "You can use the [`precision_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) function from `sklearn` to calculate the precision. It works much like the `accuracy_score` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.5\n",
    "\n",
    "Calculate the testing precision when the value of `tau` for thresholding is one of $[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]$. Create a plot where the x-axis is `tau` and the y-axis is precision.\n",
    "\n",
    "[your solution should be plotted below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAU:  0.5 Testing precision: 0.809091\n",
      "TAU:  0.6 Testing precision: 0.848178\n",
      "TAU:  0.7 Testing precision: 0.890661\n",
      "TAU:  0.8 Testing precision: 0.920548\n",
      "TAU:  0.9 Testing precision: 0.954704\n",
      "TAU:  0.95 Testing precision: 0.972350\n",
      "TAU:  0.99 Testing precision: 0.989474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-4172b90181d04a97bff2f28239fd6365\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4172b90181d04a97bff2f28239fd6365\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4172b90181d04a97bff2f28239fd6365\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c2f0a21c871c8a52cb6b6de9cfbde0fb\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"tau\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"precision\", \"scale\": {\"zero\": false}}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-c2f0a21c871c8a52cb6b6de9cfbde0fb\": [{\"tau\": 0.5, \"precision\": 0.8090909090909091}, {\"tau\": 0.6, \"precision\": 0.8481781376518218}, {\"tau\": 0.7, \"precision\": 0.8906605922551253}, {\"tau\": 0.8, \"precision\": 0.9205479452054794}, {\"tau\": 0.9, \"precision\": 0.9547038327526133}, {\"tau\": 0.95, \"precision\": 0.9723502304147466}, {\"tau\": 0.99, \"precision\": 0.9894736842105263}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this function for deliverable 3.5\n",
    "def threshold(probs, tau):\n",
    "    return np.where(probs[:,1] > tau, 1, 0)\n",
    "\n",
    "# your logistic regression code here\n",
    "taus = [0.5,0.6,0.7,0.8,0.9,0.95,0.99]\n",
    "precisions = []\n",
    "for t in taus:\n",
    "    classifier = SGDClassifier(loss='log', max_iter=1000, tol=1.0e-12, random_state=123)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    proba = (classifier.predict_proba(X_test))\n",
    "    this_precision = precision_score(Y_test, threshold(proba, t))\n",
    "    precisions.append(this_precision)\n",
    "    print(\"TAU: \", t, \"Testing precision: %0.6f\" % this_precision)\n",
    "    \n",
    "df = pd.DataFrame({\"tau\": taus,\n",
    "                   \"precision\":precisions})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x=\"tau\",\n",
    "    y=alt.Y(\"precision\",scale=alt.Scale(zero=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.6\n",
    "\n",
    "Describe what you observe with thresholding (e.g., what happens to precision as the threshold increases?), and explain why you think this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My answer\n",
    "As the threshold increases, the precision increases -- which makes sense because the precision is is giving us the percentage of 1s that we correctly classified as 1. If we are only classifying 1s that have a 99% likelihood of being a 1 (e.g., if tau is 0.99), then our precision is going to be really high, because we are only classifying 1s that we are REALLY sure (99% sure) are actually \"1\"s. Alternatively, if we set our tau really low, then our precision will be lower, because if we are allowing things that have a 50% probability of being a 1 (if tau is 0.5) to be classified as a 1, then we will be more likely to get some incorrectly classified 1s in there, making our precision value decrease -- all of this is represented in the chart: as the tau gets higher, so does the precision, as the tau gets lower, so does the precision.\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Sparse learning [5604: 5 points; 4604: +3 EC points]\n",
    "\n",
    "Add the `penalty` argument to `SGDClassifier` and set the value to `'l1'`, which tells the algorithm to use L1 regularization instead of the default L2. Recall from lecture that L1 regularization encourages weights to stay at exactly $0$, resulting in a more \"sparse\" model than L2. You should see this effect if you examine the values of `classifier.coef_`.\n",
    "\n",
    "#### Deliverable 4.1: \n",
    "\n",
    "Write a function to calculate the number of features whose weights are nonzero when using L1 regularization. Calculate the number of nonzero feature weights when `alpha` is one of $[0.00001, 0.0001, 0.001, 0.01, 0.1]$. Create a plot where the x-axis is `alpha` and the y-axis is the number of nonzero weights, using a log scale for the x-axis.\n",
    "\n",
    "[your solution should be plotted below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiejsmith/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-2f06eb588de24a119609975883e301ca\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2f06eb588de24a119609975883e301ca\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2f06eb588de24a119609975883e301ca\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-20712c0cee21fb753f549c8489e507f3\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"alpha\", \"scale\": {\"type\": \"log\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"non zero weights\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-20712c0cee21fb753f549c8489e507f3\": [{\"alpha\": 1e-05, \"non zero weights\": 10739}, {\"alpha\": 0.0001, \"non zero weights\": 3065}, {\"alpha\": 0.001, \"non zero weights\": 174}, {\"alpha\": 0.01, \"non zero weights\": 7}, {\"alpha\": 0.1, \"non zero weights\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "def numNonZero(a):\n",
    "    classifier = SGDClassifier(alpha=a, loss='log', penalty='l1', max_iter=1000, tol=1.0e-12, random_state=123)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    weights = classifier.coef_[0]\n",
    "    non_zero = 0\n",
    "    for w in weights:\n",
    "        if w > 0.0 or w < 0.0:\n",
    "            non_zero += 1\n",
    "    return non_zero\n",
    "    \n",
    "alphas = [0.00001,0.0001,0.001,0.01,0.1]\n",
    "num_nonzeros = []\n",
    "for a in alphas:\n",
    "    num_nonzeros.append(numNonZero(a))\n",
    "    \n",
    "df = pd.DataFrame({\"alpha\": alphas,\n",
    "                   \"non zero weights\":num_nonzeros})\n",
    "\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('alpha', scale=alt.Scale(type='log')),\n",
    "    y='non zero weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Briefly explain your plot in a few sentences. What happens as you increase `alpha`; does that make sense?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My answer:\n",
    "As alpha is increased, the number of non zero weights gets closer to zero (and eventually becomes zero). This does make sense because as we raise the L1 regularization hyperparam, the model is incentivized to keep the weights close to zero, so as alpha is increased (and thus as our regularization strength is increased), the weights in theory should get close to zero. And this chart proves this theory, because as alpha is increased, most of the weights (or all of the weights) become zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
