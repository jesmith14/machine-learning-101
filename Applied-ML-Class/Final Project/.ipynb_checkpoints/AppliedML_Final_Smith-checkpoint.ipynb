{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Machine Learning\n",
    "\n",
    "### Project\n",
    "\n",
    "In this class, we have worked to understand both the general principles of machine learning methods and the lower-level details required to get specific machine learning techniques to work in practice. For this project, you will apply what you have learned in this course to formulate and answer your own question using ML methods.\n",
    "\n",
    "**Important:** Be sure to include code and answers in the correct cells of the notebook. Otherwise you might not get full credit for your work.\n",
    "\n",
    "Please use this notebook to turn in your work. \n",
    "\n",
    "Points: 70\n",
    "\n",
    "You will be graded based on:\n",
    "1. __Technical completeness__. _(50 points)_ \n",
    "\n",
    "Did you meet the technical requirements for the project? For instance, did you describe hyperparameter tuning and include plots, where necessary.\n",
    "\n",
    "2. __Creativity, imagination and ambition__. _(10 points)_ \n",
    "\n",
    "Did you form an interesting, creative and ambitious question, and explain why it is important to answer that question?\n",
    "\n",
    "_Note: downloading a ready-made dataset you find online (e.g. on Kaggle) and answering a question that is already defined for you will make it hard to get full points for creativity, imagination and ambition. (Unless you do something else interesting and ambitious, e.g. analyze attributes of a specific model very closely.) To get full points for creativity/imagination/ambition you will need to think a little a bit more. The bar will be higher for 5604 students._\n",
    "\n",
    "3. __Presentation__. _(10 points)_ \n",
    "\n",
    "Did you do a good job presenting your results? Would your notebook make sense to a person who was not familiar with your project? You should take time to write clearly, simplify your code and explain what you are doing in your notebook. At minimum:\n",
    "\n",
    "- Make sure your plots are well-labeled and appropriately scaled, delete code that does not work correctly, and be sure to mix code and text so that readers can easily understand your work. \n",
    "- Check out [this](https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/) blog post for a nice example of how to present a data analysis clearly.\n",
    "- Put yourself in the reader's shoes. What would be confusing? Annoying? Helpful? Pretend you don't know anything about your project. What information needs to be presented first? What information needs to be presented last?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question \n",
    "\n",
    "_Using this cell, please write a short, clear paragraph explaining what question you plan to answer in this notebook. Your question can be narrow (e.g. can we predict a dog's height from its weight) or broad (e.g. what features are important or unimportant in predicting the price of a house). Briefly describe why your question is important and how you plan to answer. Be sure to explain what is imaginative, creative or ambitious about your planned work! For instance, will you spend a lot of time defining new features, will you be working with hard-to-get data, will your work inform a major theoretical debate? Be sure to ask a question you can actually start to answer using machine learning techniques!_\n",
    "\n",
    "\n",
    "The question that I plan to answer in this notebook is \"given one or several words as input, can I predict what I will say next based on my personal writing style?\" This question is important and very interesting to me because I am curious what an ML model that is trained on my personal data will be able to come up with for a sentence completion NLP model. I have been avidly writing (typing) journal entries since 2016, so I have hundreds of pages of typed up thoughts about my life, and I am very curious what sort of topics often come up in my life and if those will come through in the sentence generation model I create! I think this is pretty imaginative and creative because I have been dreaming of using my personal journal data for years in some capacity, I just wasn't sure what I could do with it until I took this class and had a fun idea to see if I could build a model to predict what I might say next based on what I've said in the past. The data wasn't hard to gather, but I did have to put some significant time into sorting it to make it easier to read it and then to clean it and get it into the format that I needed to create the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "_Using this cell, please write a short, clear paragraph explaining what data you will use to answer your question. You do not need to go gather custom datasets for this class, although you are welcome to do so. Just downloading data from Kaggle is fine, although you are highly encouraged to think a little harder and more creatively when you do the project. There are many, many places to find interesting datasets online related to many topics like music, politics, sports, transportation, etc. Data gathering is one way to make your project more creative, but you are not necessarily expected to take on a major data gathering effort. Be sure to describe how you plan to split between the training and test sets, if this is not defined for you. You might want to check out Google's [dataset search](https://datasetsearch.research.google.com/), [data is plural](https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0) or Prof. Keegan's [list of datasets](https://medium.com/information-expositions/list-of-lists-of-datasets-c9bf52370755)_.\n",
    "\n",
    "\n",
    "\n",
    "My dataset for this project is a corpus of text files from my personal journals. I have been typing online journals since 2016, with at least several entries of anywhere from 2-20 pages every single month since then. Since my question that I am trying to answer is \"given one or several words, can I predict what I will say next based on my personal writing style?\" -- I think this is the perfect dataset to tackle this question, because I will be training the model on my own writing over the last 5 years. I will be using 2 different kinds of models with different feature engineering strategies: (1) a simple unigram model where the features are the probabilities of the words existing in my corpus of words; and (2) a bigram markov chain sentence model where the features are the probability of the next occuring word in a sentence based on word that came before it, calculated from the probabilities and frequencies of my combinations of 2 words that I commonly use in my journals. I am curious if I will be able to personally \"audit\" or \"test\" this model outside of traditional performance metrics by checking if the resulting sentences are believable to me as something that I might actually say!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Loop through all journal documents and create an array where each element is the words in the documents in order\n",
    "- This will be used in different ways for both the unigram and the bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words total:  178877\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "## Code for data preprocessing \n",
    "\n",
    "# Include your code to load, clean and split data in this cell. You must complete this step in the project.\n",
    "import docx2txt\n",
    "months = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "days = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
    "years= [16,17,18,19,20,21]\n",
    "word_arr = []\n",
    "end_words = []\n",
    "corpus = \"\" #this is used for the unigram model\n",
    "for m in months:\n",
    "    for d in days:\n",
    "        for y in years:\n",
    "            try:\n",
    "                my_text = docx2txt.process(\"data_files/{0}_{1}_{2}.docx\".format(m,d,y))\n",
    "                for word in my_text.split():\n",
    "                    word = word.lower()# make the string lowercase\n",
    "                    word = re.sub(r'(.)\\1+', r'\\1\\1', word)# remove consecutive characters that are repeated more than twice\n",
    "                    word = re.sub(r'#\\([^()]*\\)', ' ', word)# remove special characters, keep punctuation\n",
    "                    word = word.replace(\",\", \"\")#remove commas\n",
    "                    if word[-1] in ['.','!','?'] and word != '.':\n",
    "                        end_words.append(word) #add end words to the end word array\n",
    "                        corpus += word + \" \"\n",
    "                        continue\n",
    "                    word = re.sub('[^a-z]', ' ', word) #get rid of anything non alphanumeric\n",
    "                    word = word.replace(\" \", \"\")#get rid of spaces\n",
    "                    if word == '': #get rid of edge cases where the word is an empty string\n",
    "                        continue\n",
    "                    word_arr.append(word)\n",
    "                    corpus += word + \" \"\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "print(\"Number of words total: \", len(word_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: CREATE THE DATAFRAME FOR THE BIGRAM MODEL\n",
    "- Create a pandas dataframe to store all of the words and their subsequent words, with the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict_df = pd.DataFrame(columns = ['lead', 'follow', 'freq'])\n",
    "dict_df['lead'] = word_arr\n",
    "follow = word_arr[1:]\n",
    "follow.append('EndWord')\n",
    "dict_df['follow'] = follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the frequencies of all of the word pairs and add it to the datafram\n",
    "dict_df['freq']= dict_df.groupby(by=['lead','follow'])['follow'].transform('count')\n",
    "#drop any of the duplicate rows (same word combination)\n",
    "dict_df = dict_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead</th>\n",
       "      <th>follow</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear</td>\n",
       "      <td>diary</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diary</td>\n",
       "      <td>what</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what</td>\n",
       "      <td>an</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>interesting</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interesting</td>\n",
       "      <td>life</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lead       follow  freq\n",
       "0         dear        diary    98\n",
       "1        diary         what     4\n",
       "2         what           an     9\n",
       "3           an  interesting    26\n",
       "4  interesting         life     2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to training and testing sets\n",
    "train_dict_df = dict_df[:55811] #about 80% of data\n",
    "test_dict_df = dict_df[55811:] #about 20% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pivot_df = train_dict_df.pivot(index ='lead', columns='follow', values='freq').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>follow</th>\n",
       "      <th>a</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abcs</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>...</th>\n",
       "      <th>youve</th>\n",
       "      <th>ytt</th>\n",
       "      <th>z</th>\n",
       "      <th>zack</th>\n",
       "      <th>zacks</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abcs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomen</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "follow       a  abandon  abandoned  abcs  abdomen  abilities  ability  able  \\\n",
       "lead                                                                          \n",
       "a          1.0      0.0        0.0   0.0      0.0        0.0      0.0   0.0   \n",
       "abandon    0.0      0.0        0.0   0.0      0.0        0.0      0.0   0.0   \n",
       "abandoned  0.0      0.0        0.0   0.0      0.0        0.0      0.0   0.0   \n",
       "abcs       0.0      0.0        0.0   0.0      0.0        0.0      0.0   0.0   \n",
       "abdomen    0.0      0.0        0.0   0.0      0.0        0.0      0.0   0.0   \n",
       "\n",
       "follow     about  above  ...  youve  ytt    z  zack  zacks  zen  zero  zip  \\\n",
       "lead                     ...                                                 \n",
       "a            0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0  0.0   \n",
       "abandon      0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0  0.0   \n",
       "abandoned    0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0  0.0   \n",
       "abcs         0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0  0.0   \n",
       "abdomen      0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0  0.0   \n",
       "\n",
       "follow     zone  zoom  \n",
       "lead                   \n",
       "a           0.0   1.0  \n",
       "abandon     0.0   0.0  \n",
       "abandoned   0.0   0.0  \n",
       "abcs        0.0   0.0  \n",
       "abdomen     0.0   0.0  \n",
       "\n",
       "[5 rows x 7284 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity checking my data here\n",
    "#this is in almost every document, so it makes sense that there would be a high likelihood of these two\n",
    "#occuring one after the other!\n",
    "train_pivot_df.loc[\"dear\"]['diary'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7284 entries, a to zoom\n",
      "Columns: 7284 entries, a to zoom\n",
      "dtypes: float64(7284)\n",
      "memory usage: 405.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_pivot_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and tuning\n",
    "\n",
    "_Using this cell, please write a short, clear paragraph explaining how you selected and tuned your model for the project. You must answer the following questions in this cell (1) Why is your model an appropriate choice for your data? (2) What hyperparameters does your model have and how did you select them? (3) What features did you choose and why?_\n",
    "\n",
    "You must, at minimum:\n",
    "1. Engineer one feature (unigram vs. bigram)\n",
    "2. Tune one hyperparameter (smoothing)\n",
    "3. Make a plot or table examining performance of your model under different parameter settings (perplexity with different smoothing for bigram vs. ngram)\n",
    "\n",
    "### What I did for model selection and tuning:\n",
    "- I trained two different kinds of models with different feature engineering: a unigram model and a bigram model\n",
    "- For each of the 2 models, I tested the performance (measuring perplexity as performance) with different choices for the \"smoothing\", which is the assigned probability for words or combinations of words that don't exist in the training dataset\n",
    "- I plotted the impact that smoothing had on the perplexity (performance) for each separate model, and then I plotted the two different models together to see which one performed best in the next section.\n",
    "\n",
    "Your answer here to the other questions:\n",
    "1. My model was an appropriate choice for my data because in order to create a language model (LM) that does sentence generation, I need to know the probabilities of the words that I am going to be generating. This can be done through models with different n-grams as the feature engineering step, where the features in the model are some sort of probability of the words based on n previous words. For my models, I did a unigram feature engineering, where the features were the probability of the words based on their occurence in the entire corpus of training data. And I did a bigram feature engineering, where the features were the probability of the words based on their occurence coming after the previous word in my corpus of training data.\n",
    "2. My hyperparameter that I chose to play with was the 'smoothing' value of my models. Smoothing is the value (probability) that is assigned to the words (or combinations of 2 words for the bigram) that our model hasn't encountered yet. This helps us not get a value of infinity when we calculate the performance with perplexity.\n",
    "3. For the features, I ended up choosing all of the words in my corpus of training data. For the unigram model, the values were the probability of that word occuring in the text, and for the bigram model the values were the probability of that word occuring after the previous word based on the training corpus. So the features for my unigram model looked like a dictionary, and the features for my bigram model looked like an 2-dimensional array, where the columns and rows were all the combinations of words that I could encounter in my corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for model selection and tuning.  Please include your code for model selection and tuning in this cell\n",
    "\n",
    "#All code for model selection and tuning is in the cells below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNIGRAM MODEL:\n",
    "- FEATURE ENGINEERED --> THIS IS USING UNIGRAMS INSTEAD OF BIGRAMS TO ALLOCATE FREQUENCIES IN THE MODEL\n",
    "- TUNING THE MODEL WITH SMOOTHING\n",
    "- PLOTTING THE PERPLEXITY AT DIFFERENT LEVELS OF SMOOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the corpus into train and test sets\n",
    "train_corpus = corpus[:625395]\n",
    "test_corpus = corpus[625395:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE PERFORMANCE (PERPLEXITY) ON TRAIN AND TEST SETS\n",
    "from nltk import tokenize\n",
    "train_sentences = tokenize.sent_tokenize(train_corpus)\n",
    "test_sentences = tokenize.sent_tokenize(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNIGRAM MODEL: come up with a dictionary that has every word in the corpus and it's frequency\n",
    "import collections\n",
    "def unigramModel(smoothing):\n",
    "    unigram_model = collections.defaultdict(lambda: smoothing)\n",
    "    sum_all_counts = len(word_arr)\n",
    "    for word in train_corpus.split():\n",
    "        if word in unigram_model:\n",
    "            unigram_model[word] += 1\n",
    "        else:\n",
    "            unigram_model[word] = 1\n",
    "\n",
    "    for word in unigram_model:\n",
    "        unigram_model[word] = unigram_model[word]/sum_all_counts\n",
    "    return unigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for word in testset:\n",
    "        N += 1\n",
    "        prob_of_word = model[word]\n",
    "        perplexity = perplexity + (1/prob_of_word)\n",
    "    perplexity = pow(perplexity, 1/float(N))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def getPerplexity(sentences, smoothing_params):\n",
    "    smoothing_params = [0.5, 0.1, 0.01, 0.001, 0.0001, 0.000001]\n",
    "    perplexities = []\n",
    "    for smoothing in smoothing_params:\n",
    "        smoothedModel = unigramModel(smoothing)\n",
    "        sum_perplexity = []\n",
    "        for sentence in sentences:\n",
    "            sentence_perp = perplexity(sentence, smoothedModel)\n",
    "            sum_perplexity.append(sentence_perp)\n",
    "        avg_perplexity = np.asarray(sum_perplexity).mean()\n",
    "        perplexities.append(avg_perplexity)\n",
    "    return(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_params = [0.5, 0.1, 0.01, 0.001, 0.0001, 0.000001]\n",
    "test_perplexities_unigram = getPerplexity(test_sentences, smoothing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot or table #1\n",
    "\n",
    "# Include a plot or table explaining how you selected and tuned your model. You must complete this step in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ad1cf94cc400408faeaf78d08fcafa52\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ad1cf94cc400408faeaf78d08fcafa52\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ad1cf94cc400408faeaf78d08fcafa52\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e9e606ecf7316075bd50c21ef53efeb9\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Smoothing Value\", \"scale\": {\"type\": \"log\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"Perplexity\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-e9e606ecf7316075bd50c21ef53efeb9\": [{\"Smoothing Value\": 0.5, \"Perplexity\": 476.72558898618354}, {\"Smoothing Value\": 0.1, \"Perplexity\": 476.76010950081377}, {\"Smoothing Value\": 0.01, \"Perplexity\": 477.1224643712439}, {\"Smoothing Value\": 0.001, \"Perplexity\": 480.5881238056932}, {\"Smoothing Value\": 0.0001, \"Perplexity\": 514.3037869060355}, {\"Smoothing Value\": 1e-06, \"Perplexity\": 4160.859283476815}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "df = pd.DataFrame({\"Smoothing Value\": smoothing_params,\n",
    "                   \"Perplexity\":test_perplexities_unigram})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('Smoothing Value', scale=alt.Scale(type='log')),\n",
    "    y='Perplexity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATIC BIGRAM MODEL:\n",
    "- FEATURE ENGINEERED --> THIS IS USING BIGRAMS INSTEAD OF UNIGRAMS TO ALLOCATE FREQUENCIES IN THE MODEL\n",
    "- STATIC BIGRAM MODEL (we choose the next word as the one with the highest probability of being next)\n",
    "- TUNING THE MODEL WITH SMOOTHING\n",
    "- PLOTTING THE PERPLEXITY AT DIFFERENT LEVELS OF SMOOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>follow</th>\n",
       "      <th>a</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abcs</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>...</th>\n",
       "      <th>youve</th>\n",
       "      <th>ytt</th>\n",
       "      <th>z</th>\n",
       "      <th>zack</th>\n",
       "      <th>zacks</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abcs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomen</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "follow            a  abandon  abandoned  abcs  abdomen  abilities  ability  \\\n",
       "lead                                                                         \n",
       "a          0.000295      0.0        0.0   0.0      0.0        0.0      0.0   \n",
       "abandon    0.000000      0.0        0.0   0.0      0.0        0.0      0.0   \n",
       "abandoned  0.000000      0.0        0.0   0.0      0.0        0.0      0.0   \n",
       "abcs       0.000000      0.0        0.0   0.0      0.0        0.0      0.0   \n",
       "abdomen    0.000000      0.0        0.0   0.0      0.0        0.0      0.0   \n",
       "\n",
       "follow     able  about  above  ...  youve  ytt    z  zack  zacks  zen  zero  \\\n",
       "lead                           ...                                            \n",
       "a           0.0    0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "abandon     0.0    0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "abandoned   0.0    0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "abcs        0.0    0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "abdomen     0.0    0.0    0.0  ...    0.0  0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "\n",
       "follow     zip  zone      zoom  \n",
       "lead                            \n",
       "a          0.0   0.0  0.000295  \n",
       "abandon    0.0   0.0  0.000000  \n",
       "abandoned  0.0   0.0  0.000000  \n",
       "abcs       0.0   0.0  0.000000  \n",
       "abdomen    0.0   0.0  0.000000  \n",
       "\n",
       "[5 rows x 7284 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Feature engineering. Please include your code for feature engineering in this cell. \n",
    "#sum all of the frequencies of the following words for each word\n",
    "sum_words = train_pivot_df.sum(axis=1)\n",
    "#divide these frequencies by the total frequency for each row to get a probability between 0 and 1\n",
    "train_pivot_df = train_pivot_df.apply(lambda x: x/sum_words)\n",
    "#in theory all of the rows should sum up to 1 now!\n",
    "train_pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexityStaticBigram(testset, model, smoothing):\n",
    "    #split the sentence into words\n",
    "    #find the probability of the two combination of words\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    ngrams = []\n",
    "    for i in range(1, len(testset)):\n",
    "        ngram = ' '.join(testset[i-2+1:i+1])\n",
    "        ngrams.append(ngram)\n",
    "    N = 0\n",
    "    for combination in ngrams:\n",
    "        word1,word2 = combination.split()\n",
    "        N += 1\n",
    "        try:\n",
    "            prob_of_word = model.loc[word1,word2]\n",
    "        except:\n",
    "            prob_of_word = smoothing\n",
    "        if prob_of_word == 0:\n",
    "            prob_of_word = smoothing\n",
    "        perplexity = perplexity + (1/prob_of_word)\n",
    "    if N == 0:\n",
    "        print(testset)\n",
    "    perplexity = pow(perplexity, 1/float(N))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerplexityNgrams(sentences):\n",
    "    smoothing_params = [0.5, 0.1, 0.01, 0.001, 0.0001, 0.000001]\n",
    "    perplexities = []\n",
    "    for smoothing in smoothing_params:\n",
    "        sum_perplexity = []\n",
    "        for sentence in sentences:\n",
    "            if len(sentence.split()) > 1:\n",
    "                sentence_perp = perplexityStaticBigram(sentence, train_pivot_df, smoothing)\n",
    "                sum_perplexity.append(sentence_perp)\n",
    "        avg_perplexity = np.asarray(sum_perplexity).mean()\n",
    "        perplexities.append(avg_perplexity)\n",
    "    return(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perplexities_bigram = getPerplexityNgrams(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot or table #2\n",
    "\n",
    "# Include a plot or table explaining how you selected and tuned your model. You must complete this step in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-4a199c915f794f68b933d305840eeec4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4a199c915f794f68b933d305840eeec4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4a199c915f794f68b933d305840eeec4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-8e6c895c53725673cdb0b53ea7103233\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Smoothing Value\", \"scale\": {\"type\": \"log\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"Perplexity\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-8e6c895c53725673cdb0b53ea7103233\": [{\"Smoothing Value\": 0.5, \"Perplexity\": 2.5657481207537485}, {\"Smoothing Value\": 0.1, \"Perplexity\": 2.784380622173457}, {\"Smoothing Value\": 0.01, \"Perplexity\": 4.942714793575661}, {\"Smoothing Value\": 0.001, \"Perplexity\": 24.498041491723868}, {\"Smoothing Value\": 0.0001, \"Perplexity\": 211.11798141380393}, {\"Smoothing Value\": 1e-06, \"Perplexity\": 20340.732900885647}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Smoothing Value\": smoothing_params,\n",
    "                   \"Perplexity\":test_perplexities_bigram})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('Smoothing Value', scale=alt.Scale(type='log')),\n",
    "    y='Perplexity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "_Using this cell, please write a short, clear paragraph explaining your results. In this class, we have mostly focused on accuracy. It is OK to measure your results in another quantitative way (e.g. precision or likelihood). Whatever you pick, make sure you are clear on what you are doing, and make sure you explain why your measurement of success makes sense._\n",
    "\n",
    "First, I wanted to explain that I am using perplexity as a measure of performance given that this is an unlabeled and unsupervised language model. The lower the perplexity, the better the model is at predicting new words / sequences of words that don't exist in the training corpus. My results are pretty interesting for these experiments. First, I noticed that my unigram model performed significantly better than my bigram model when my smoothing value was really low, but my bigram model began to outperform my unigram model significantly at a smoothing value of about 0.000015. In general, it makes sense that as my smoothing goes up, the perplexity goes down, because that means that I am assigning a higher probability to words that I haven't encountered yet, and so it will perform much better on the test set when it encounters new words. However, choosing a model with a very high smoothing value would end up giving me a model with high test performance but really low training performance, because I would be introducing a lot of bias into the model (though I would be reducing the variance of the model).\n",
    "\n",
    "Ultimately, I think that my bigram model is better than my unigram model on average across smooething values, so that is the model that I ended up deciding to look deeper into for my error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5657481207537485, 2.784380622173457, 4.942714793575661, 24.498041491723868, 211.11798141380393, 20340.732900885647]\n",
      "[476.72558898618354, 476.76010950081377, 477.1224643712439, 480.5881238056932, 514.3037869060355, 4160.859283476815]\n",
      "[0.5, 0.1, 0.01, 0.001, 0.0001, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "## Code \n",
    "\n",
    "# Include code showing how you arrived at your results. You must complete this step in the project.\n",
    "print(test_perplexities_bigram)\n",
    "print(test_perplexities_unigram)\n",
    "print(smoothing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-8698b42e09d340a890d90f7d9fe3dd4b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8698b42e09d340a890d90f7d9fe3dd4b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8698b42e09d340a890d90f7d9fe3dd4b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-04c90df19c91b1a2562ac7b8041b9ce9\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Model Type\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"Smoothing Value\", \"scale\": {\"type\": \"log\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"Perplexity\", \"scale\": {\"type\": \"log\"}}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-04c90df19c91b1a2562ac7b8041b9ce9\": [{\"Smoothing Value\": 0.5, \"Model Type\": \"unigram\", \"Perplexity\": 476.72558898618354}, {\"Smoothing Value\": 0.1, \"Model Type\": \"unigram\", \"Perplexity\": 476.76010950081377}, {\"Smoothing Value\": 0.01, \"Model Type\": \"unigram\", \"Perplexity\": 477.1224643712439}, {\"Smoothing Value\": 0.001, \"Model Type\": \"unigram\", \"Perplexity\": 480.5881238056932}, {\"Smoothing Value\": 0.0001, \"Model Type\": \"unigram\", \"Perplexity\": 514.3037869060355}, {\"Smoothing Value\": 1e-06, \"Model Type\": \"unigram\", \"Perplexity\": 4160.859283476815}, {\"Smoothing Value\": 0.5, \"Model Type\": \"bigram\", \"Perplexity\": 2.5657481207537485}, {\"Smoothing Value\": 0.1, \"Model Type\": \"bigram\", \"Perplexity\": 2.784380622173457}, {\"Smoothing Value\": 0.01, \"Model Type\": \"bigram\", \"Perplexity\": 4.942714793575661}, {\"Smoothing Value\": 0.001, \"Model Type\": \"bigram\", \"Perplexity\": 24.498041491723868}, {\"Smoothing Value\": 0.0001, \"Model Type\": \"bigram\", \"Perplexity\": 211.11798141380393}, {\"Smoothing Value\": 1e-06, \"Model Type\": \"bigram\", \"Perplexity\": 20340.732900885647}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Plot or table \n",
    "# Include a plot or table explaining your results. You must complete this step in the project.\n",
    "#FINAL PLOT DETAILING THE DIFFERENCE BETWEEN THE BIGRAM AND UNIGRAM MODEL WITH DIFFERENT SMOOTHING PARAMS\n",
    "df = pd.DataFrame({\"Smoothing Value\": smoothing_params + smoothing_params,\n",
    "                   \"Model Type\": ['unigram'] * len(smoothing_params) + ['bigram'] * len(smoothing_params),\n",
    "                   \"Perplexity\":test_perplexities_unigram + test_perplexities_bigram})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('Smoothing Value', scale=alt.Scale(type='log')),\n",
    "    color='Model Type',\n",
    "    y=alt.Y('Perplexity', scale=alt.Scale(type='log')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type of feature/model | Smoothing Params | Perplexity |\n",
    "|---------|---------------------|---------|\n",
    "| Bigram   |   0.5                  |2.5657481207537485|\n",
    "| Bigram   |   0.1                  |2.784380622173457|\n",
    "| Bigram   |   0.01                  |4.942714793575661|\n",
    "| Bigram   |   0.001                  |24.498041491723868|\n",
    "| Bigram   |   0.0001                  |211.11798141380393|\n",
    "| Bigram   |   0.000001                |20340.732900885647|\n",
    "| Unigram  |   0.5                  |476.72558898618354|\n",
    "| Unigram   |   0.1                  |476.76010950081377|\n",
    "| Unigram   |   0.01                  |477.1224643712439|\n",
    "| Unigram   |   0.001                  |480.5881238056932|\n",
    "| Unigram   |   0.0001                  |514.3037869060355|\n",
    "| Unigram   |   0.000001                |4160.859283476815|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "_Using this cell, please write a short, clear paragraph explaining what errors your model seems to be making, and offer a brief explanation based on your code below._ \n",
    "\n",
    "You must:\n",
    "1. Perform some error analysis technique, such as making a confusion matrix or examining model mistakes.\n",
    "\n",
    "\n",
    "### Description of error analysis technique:\n",
    "\n",
    "1. First, I decided to analyze the error on my bigram model since it peformed better than the unigram model. \n",
    "2. I also decided to analye the error manually since it is in theory attempting to generate sentences that sound like something that I would write, so I can determine if a generated sentence is convincing to me that I might have written it. \n",
    "3. I was also curious if the static bigram model that I made would produce sentences that were better or worse than a bigram model that was based on a more distributed version of probabilities. I ended up creating two different functions based on my bigram model:\n",
    "- One of the functions assigns the next word in the sentence only based on the word with the highest probability to occur next. This means that if I input the same intro of a sentence, I will always get the same ending of the sentence back.\n",
    "- The other function assigns the next word in the sented based on the distribution of probabilities of next words. This means that if I input the same intro of a sentence, I will get a different ending of a sentence back, because I am randomly choosing next words based on their probability of being next over the distribution of probabilities of next words based on the previous word!\n",
    "4. Finally, I manually checked both of these models with the same inputs to see if any of the sentences were convincing to me as something that I could have written, and also which type of model I thought was more convincing! Overall, I discovered that my static model was producing some specific errors (such as getting stuck in loops like \"i am i am i am\") and both models were producing errors by creating sentences that weren't gramatically correct (or sentences that just semantically didn't make sense). I describe my analysis more fully in the summary and conclusions cell at the bottom of this notebook \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error analysis\n",
    "\n",
    "# Include code for error analysis here, to justify your conclusions. \n",
    "# You might make a confusion matrix, sample misclassifier data, analyze learned weights, or use any other method \n",
    "# discussed in class, or which makes sense for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "all_words = train_pivot_df.columns\n",
    "\n",
    "def make_a_sentence_static_bigram(start_of_sentence):\n",
    "    word= start_of_sentence.split()[-1]\n",
    "    word = word.lower()\n",
    "    sentence=start_of_sentence.split()\n",
    "    while len(sentence) < 30:\n",
    "        #this is the next word with the highest probability of occuring\n",
    "        next_word = train_pivot_df.loc[[word]].apply(lambda x: train_pivot_df.columns[x.argmax()], axis = 1)[0]\n",
    "        prob_of_next_word = train_pivot_df.loc[word,next_word]\n",
    "        #this code is to determine when we have reached a likely end of sentence by encountering an \"end-word\"\n",
    "        if next_word == 'EndWord':\n",
    "                continue\n",
    "        elif len(sentence) > 10 and (next_word + '!') in end_words:\n",
    "            sentence.append(next_word + '!')\n",
    "            break\n",
    "        elif len(sentence) > 10 and (next_word + '.') in end_words:\n",
    "            sentence.append(next_word + '.')\n",
    "            break\n",
    "        elif len(sentence) > 10 and(next_word + '?') in end_words:\n",
    "            sentence.append(next_word + '?')\n",
    "            break\n",
    "        else :\n",
    "            sentence.append(next_word)\n",
    "        word=next_word\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "all_words = train_pivot_df.columns\n",
    "\n",
    "def make_a_sentence_distributed_bigram(start_of_sentence):\n",
    "    word= start_of_sentence.split()[-1]\n",
    "    word = word.lower()\n",
    "    sentence=start_of_sentence.split()\n",
    "    while len(sentence) < 30:\n",
    "        #get the probabilities of the next potential words\n",
    "        #alternative version where I choose next word randomly based on distribution of probabilities of next words\n",
    "        probabilities_of_next_word = (train_pivot_df.iloc[train_pivot_df.index ==word].fillna(0).values)[0]\n",
    "        #choose a random word based on the distribution of probabilities\n",
    "        next_word = choice(a = all_words, p=probabilities_of_next_word)\n",
    "        \n",
    "        #this code is to determine when we have reached a likely end of sentence by encountering an \"end-word\"\n",
    "        if next_word == 'EndWord':\n",
    "                continue\n",
    "        elif len(sentence) > 10 and (next_word + '!') in end_words:\n",
    "            sentence.append(next_word + '!')\n",
    "            break\n",
    "        elif len(sentence) > 10 and (next_word + '.') in end_words:\n",
    "            sentence.append(next_word + '.')\n",
    "            break\n",
    "        elif len(sentence) > 10 and(next_word + '?') in end_words:\n",
    "            sentence.append(next_word + '?')\n",
    "            break\n",
    "        else :\n",
    "            sentence.append(next_word)\n",
    "        word=next_word\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  how am I supposed to be a lot of the i am.\n",
      "DISTRIBUTED BIGRAM:  how am I supposed to do still havent been finding solace with.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"how am I supposed to\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"how am I supposed to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  This is the AI named Jess age dear diary i am so.\n",
      "DISTRIBUTED BIGRAM:  This is the AI named Jess dear diary its strange i am.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"This is the AI named Jess\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"This is the AI named Jess\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  What I want in life is to be a lot of the i.\n",
      "DISTRIBUTED BIGRAM:  What I want in life is to be needing to visualize myself!\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"What I want in life is to\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"What I want in life is to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  My biggest goals are to be a lot of the i am.\n",
      "DISTRIBUTED BIGRAM:  My biggest goals are to believe i dont know every i should have.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"My biggest goals are to\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"My biggest goals are to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  I hope to achieve some of the i am so i am.\n",
      "DISTRIBUTED BIGRAM:  I hope to achieve these terrible for quite a quarter do of.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"I hope to achieve\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"I hope to achieve\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  I love i am so i am so i am so i.\n",
      "DISTRIBUTED BIGRAM:  I love happiness in the appropriate time i told him and how.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"I love\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"I love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  I will never know that i am so i am so i.\n",
      "DISTRIBUTED BIGRAM:  I will never know that i had only visiting you want to.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"I will never know\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"I will never know\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  What if I am so i am so i am so i.\n",
      "DISTRIBUTED BIGRAM:  What if I love you hide stuff that i dont look in.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"What if I\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"What if I\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC BIGRAM:  Dear diary i am so i am so i am so i.\n",
      "DISTRIBUTED BIGRAM:  Dear diary holy writing love i couldnt watch something similar to become.\n"
     ]
    }
   ],
   "source": [
    "print(\"STATIC BIGRAM: \", make_a_sentence_static_bigram(\"Dear diary\"))\n",
    "print(\"DISTRIBUTED BIGRAM: \", make_a_sentence_distributed_bigram(\"Dear diary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and conclusion\n",
    "\n",
    "_Using this cell, please write a short, clear paragraph describing how your results answer or do not answer your question. What are the implications of your findings? What new questions arise from your work?_\n",
    "\n",
    "What an interesting and insightful project! I discovered that my best performing model (the static bigram model) might have performed pretty well in theory, but in practice it actually produced sentences that didn't make a lot of sence in the English language and also that I didn't believe I would have written in my diary. This was in part because I noticed that assigning the next word to *always* be the word with the highest probability of coming next created some unintentional feedback loops in my model. For example, the most common word that comes after the word \"I\" is \"am\", which meant that in my static model, every time I encountered the word \"I\", my sentence would continue with \"am\", and there were many times that the sentence output was something like \"I am [word word] I am [word] I am..\" or something similar to that. In my diary entries in real life, I would definitely not be likely to write a sentence like that. However, in my distributed model where I chose to assign the next word *randomly* based on the distribution of probabilities of next words, the sentences that resulted from my model were actually relatively convincing! Sure, they weren't gramatically perfect because this is a pretty rudimentary model. However - some of them I definitely believed I could have written some version of. For example, when I inputed \"I love...\", the distributed model returend \"I love happiness in the appropriate time i told him and how\" -- this sentence used words that are really common in my day-to-day language, such as 'happiness' and the sentence was almost gramatically correct enough to be believable, using phrases such as 'in the appropriate time i told him'. On the other hand, the static model that was fed in this same input resulted in \"I love i am so i am so i am so i.\", which did not make sense to me and also fell victim to the feedback loop of 'i am' that I was discussing earlier. Overall, I learned a lot about bigram and unigram language models throughout this project and I also learned a bit about my writing style and the types of words / combinations of words that I use most often in my written diaries! The implications of these findings are that I am convinced that if I had more time to make a more robust model I could make a convincing language model of my own writing style. I am curious what would happen if I was to create a model that used trigrams or even n-grams with a higher n and if the sentences generated would be even more convincing -- but I will leave that for future work.\n",
    "\n",
    "##### Side note: if this notebook is ran again, my distributed model will produce different results for my sentence generation since it picks randomly across the distribution of probabilities - so some of the results that I analyzed above might be slightly different on a different run - but this was the way that I analyzed the first round of outputs that I tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
